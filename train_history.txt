=== Training fold 0 ===
[Fold 0] Head E1/6: train_loss=4055.3845 val_sumMSE=390.1324 (SBP=281.1146, DBP=109.0178)
[Fold 0] Head E2/6: train_loss=481.5258 val_sumMSE=401.0500 (SBP=294.2093, DBP=106.8407)
[Fold 0] Head E3/6: train_loss=464.2508 val_sumMSE=339.7662 (SBP=242.9053, DBP=96.8609)
[Fold 0] Head E4/6: train_loss=438.0200 val_sumMSE=362.9157 (SBP=262.8904, DBP=100.0253)
[Fold 0] Head E5/6: train_loss=424.9245 val_sumMSE=320.7974 (SBP=228.6783, DBP=92.1191)
[Fold 0] Head E6/6: train_loss=406.4651 val_sumMSE=315.7474 (SBP=225.5759, DBP=90.1714)
[Fold 0] Finetune E1/10: train_loss=392.4058 val_sumMSE=304.9141 (SBP=218.0173, DBP=86.8968)
[Fold 0] Finetune E2/10: train_loss=376.3994 val_sumMSE=304.9942 (SBP=218.5708, DBP=86.4234)
[Fold 0] Finetune E3/10: train_loss=360.3975 val_sumMSE=311.6166 (SBP=223.3522, DBP=88.2645)
[Fold 0] Finetune E4/10: train_loss=350.1762 val_sumMSE=318.0158 (SBP=228.0567, DBP=89.9591)
[Fold 0] Finetune E5/10: train_loss=333.7748 val_sumMSE=319.1087 (SBP=228.6954, DBP=90.4133)
[Fold 0] Finetune E6/10: train_loss=322.2963 val_sumMSE=288.2226 (SBP=205.8970, DBP=82.3256)
[Fold 0] Finetune E7/10: train_loss=309.1511 val_sumMSE=293.0073 (SBP=208.8107, DBP=84.1966)
[Fold 0] Finetune E8/10: train_loss=300.0043 val_sumMSE=306.4181 (SBP=220.3523, DBP=86.0658)
[Fold 0] Finetune E9/10: train_loss=282.4284 val_sumMSE=306.4848 (SBP=223.4281, DBP=83.0567)
[Fold 0] Finetune E10/10: train_loss=270.4927 val_sumMSE=324.3887 (SBP=238.8462, DBP=85.5425)
=== Training fold 1 ===
[Fold 1] Head E1/6: train_loss=4340.7691 val_sumMSE=372.0369 (SBP=267.9631, DBP=104.0738)
[Fold 1] Head E1/6: train_loss=4340.7691 val_sumMSE=372.0369 (SBP=267.9631, DBP=104.0738)
[Fold 1] Head E2/6: train_loss=500.8862 val_sumMSE=362.1963 (SBP=258.3057, DBP=103.8906)
[Fold 1] Head E3/6: train_loss=474.1648 val_sumMSE=352.1901 (SBP=249.9830, DBP=102.2071)
[Fold 1] Head E4/6: train_loss=452.9155 val_sumMSE=350.2040 (SBP=248.7870, DBP=101.4171)
[Fold 1] Head E4/6: train_loss=452.9155 val_sumMSE=350.2040 (SBP=248.7870, DBP=101.4171)
[Fold 1] Head E5/6: train_loss=444.7626 val_sumMSE=333.0333 (SBP=238.2243, DBP=94.8090)
[Fold 1] Head E6/6: train_loss=429.3697 val_sumMSE=333.1899 (SBP=239.9278, DBP=93.2620)
[Fold 1] Finetune E1/10: train_loss=412.9726 val_sumMSE=327.8491 (SBP=234.9329, DBP=92.9162)
[Fold 1] Finetune E2/10: train_loss=400.4627 val_sumMSE=371.3885 (SBP=268.4541, DBP=102.9345)
[Fold 1] Finetune E3/10: train_loss=387.8922 val_sumMSE=325.7449 (SBP=229.9580, DBP=95.7869)
[Fold 1] Finetune E4/10: train_loss=377.5699 val_sumMSE=314.1675 (SBP=224.6795, DBP=89.4881)
[Fold 1] Finetune E5/10: train_loss=364.6378 val_sumMSE=299.3333 (SBP=213.5038, DBP=85.8295)
[Fold 1] Finetune E6/10: train_loss=352.5096 val_sumMSE=309.7527 (SBP=224.3558, DBP=85.3969)
[Fold 1] Finetune E7/10: train_loss=341.1022 val_sumMSE=298.7801 (SBP=210.6140, DBP=88.1660)
[Fold 1] Finetune E8/10: train_loss=329.9849 val_sumMSE=306.9140 (SBP=219.5882, DBP=87.3259)
[Fold 1] Finetune E9/10: train_loss=320.8038 val_sumMSE=305.3090 (SBP=217.7875, DBP=87.5215)
[Fold 1] Finetune E10/10: train_loss=306.5899 val_sumMSE=289.1103 (SBP=207.5080, DBP=81.6023)
=== Training fold 2 ===
[Fold 2] Head E1/6: train_loss=4278.4541 val_sumMSE=387.7230 (SBP=287.6344, DBP=100.0886)
[Fold 2] Head E2/6: train_loss=491.0493 val_sumMSE=360.6137 (SBP=261.5407, DBP=99.0730)
[Fold 2] Head E3/6: train_loss=475.0993 val_sumMSE=363.1381 (SBP=262.6228, DBP=100.5153)
[Fold 2] Head E4/6: train_loss=455.3028 val_sumMSE=353.4216 (SBP=252.8811, DBP=100.5406)
[Fold 2] Head E5/6: train_loss=444.9100 val_sumMSE=330.7074 (SBP=238.2223, DBP=92.4851)
[Fold 2] Head E6/6: train_loss=427.4515 val_sumMSE=322.8796 (SBP=231.0076, DBP=91.8720)
[Fold 2] Finetune E1/10: train_loss=412.1352 val_sumMSE=381.7874 (SBP=278.5008, DBP=103.2866)
[Fold 2] Finetune E2/10: train_loss=398.6771 val_sumMSE=347.6461 (SBP=250.6423, DBP=97.0037)
[Fold 2] Finetune E3/10: train_loss=388.1473 val_sumMSE=340.5514 (SBP=245.1120, DBP=95.4394)
[Fold 2] Finetune E4/10: train_loss=376.7534 val_sumMSE=319.5296 (SBP=229.6273, DBP=89.9023)
[Fold 2] Finetune E5/10: train_loss=364.9346 val_sumMSE=308.4641 (SBP=221.1794, DBP=87.2847)
[Fold 2] Finetune E6/10: train_loss=353.3031 val_sumMSE=321.4751 (SBP=230.3718, DBP=91.1033)
[Fold 2] Finetune E7/10: train_loss=337.5975 val_sumMSE=322.0587 (SBP=229.2848, DBP=92.7739)
[Fold 2] Finetune E8/10: train_loss=327.4559 val_sumMSE=319.8571 (SBP=228.2257, DBP=91.6314)
[Fold 2] Finetune E9/10: train_loss=316.1273 val_sumMSE=310.1783 (SBP=220.5393, DBP=89.6391)
[Fold 2] Finetune E10/10: train_loss=305.1729 val_sumMSE=361.0319 (SBP=264.2162, DBP=96.8158)
=== Training fold 3 ===
[Fold 3] Head E1/6: train_loss=4046.0008 val_sumMSE=431.2891 (SBP=321.5920, DBP=109.6971)
[Fold 3] Head E2/6: train_loss=485.5756 val_sumMSE=359.6082 (SBP=263.4809, DBP=96.1273)
[Fold 3] Head E3/6: train_loss=466.1039 val_sumMSE=346.7794 (SBP=250.1209, DBP=96.6586)
[Fold 3] Head E4/6: train_loss=448.6648 val_sumMSE=334.8760 (SBP=242.2539, DBP=92.6221)
[Fold 3] Head E5/6: train_loss=431.4862 val_sumMSE=338.8927 (SBP=247.2529, DBP=91.6398)
[Fold 3] Head E6/6: train_loss=413.6913 val_sumMSE=320.7645 (SBP=234.6295, DBP=86.1350)
[Fold 3] Finetune E1/10: train_loss=398.9956 val_sumMSE=312.1818 (SBP=228.2739, DBP=83.9079)
[Fold 3] Finetune E2/10: train_loss=387.3149 val_sumMSE=303.6833 (SBP=220.2854, DBP=83.3980)
[Fold 3] Finetune E3/10: train_loss=371.5213 val_sumMSE=321.1674 (SBP=233.9514, DBP=87.2160)
[Fold 3] Finetune E4/10: train_loss=360.4985 val_sumMSE=316.9819 (SBP=231.6343, DBP=85.3476)
[Fold 3] Finetune E5/10: train_loss=347.8687 val_sumMSE=294.0872 (SBP=214.3513, DBP=79.7359)
[Fold 3] Finetune E6/10: train_loss=332.8686 val_sumMSE=309.2301 (SBP=224.7967, DBP=84.4335)
[Fold 3] Finetune E7/10: train_loss=322.4866 val_sumMSE=302.6885 (SBP=221.0828, DBP=81.6056)
[Fold 3] Finetune E8/10: train_loss=306.7997 val_sumMSE=310.8875 (SBP=227.6444, DBP=83.2431)
[Fold 3] Finetune E9/10: train_loss=294.9968 val_sumMSE=297.5439 (SBP=217.7587, DBP=79.7852)
[Fold 3] Finetune E10/10: train_loss=284.2631 val_sumMSE=287.0923 (SBP=209.9400, DBP=77.1524)
=== Training fold 4 ===
[Fold 4] Head E1/6: train_loss=3964.1331 val_sumMSE=382.0577 (SBP=276.7380, DBP=105.3197)
[Fold 4] Head E2/6: train_loss=482.9994 val_sumMSE=367.5676 (SBP=267.6439, DBP=99.9237)
[Fold 4] Head E3/6: train_loss=456.2429 val_sumMSE=401.1184 (SBP=294.7581, DBP=106.3603)
[Fold 4] Head E4/6: train_loss=440.2097 val_sumMSE=347.4855 (SBP=249.6636, DBP=97.8219)
[Fold 4] Head E5/6: train_loss=430.3029 val_sumMSE=348.0801 (SBP=252.4936, DBP=95.5865)
[Fold 4] Head E6/6: train_loss=409.7629 val_sumMSE=323.5660 (SBP=234.2114, DBP=89.3546)
[Fold 4] Finetune E1/10: train_loss=398.9244 val_sumMSE=336.0833 (SBP=242.1666, DBP=93.9167)
[Fold 4] Finetune E2/10: train_loss=384.4370 val_sumMSE=355.9878 (SBP=256.3058, DBP=99.6820)
[Fold 4] Finetune E3/10: train_loss=371.0121 val_sumMSE=316.2282 (SBP=226.1937, DBP=90.0345)
[Fold 4] Finetune E4/10: train_loss=360.3597 val_sumMSE=322.6897 (SBP=233.9955, DBP=88.6942)
[Fold 4] Finetune E5/10: train_loss=350.8952 val_sumMSE=312.5172 (SBP=226.3007, DBP=86.2165)
[Fold 4] Finetune E6/10: train_loss=329.5298 val_sumMSE=298.3376 (SBP=217.0493, DBP=81.2883)
[Fold 4] Finetune E7/10: train_loss=317.7215 val_sumMSE=309.8644 (SBP=225.2814, DBP=84.5831)
[Fold 4] Finetune E8/10: train_loss=304.2015 val_sumMSE=316.4616 (SBP=230.5843, DBP=85.8773)
[Fold 4] Finetune E9/10: train_loss=293.1740 val_sumMSE=304.5372 (SBP=222.0220, DBP=82.5152)
[Fold 4] Finetune E10/10: train_loss=284.2614 val_sumMSE=305.2209 (SBP=220.9400, DBP=84.2809)
CV sumMSE per fold: [288.22259521484375, 289.11029052734375, 308.4640808105469, 287.09234619140625, 298.337646484375] mean: 294.2453918457031
Saved submission.csv